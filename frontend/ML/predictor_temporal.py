import pandas as pd
import numpy as np
import pickle
import os
import json
from datetime import timedelta

# --- Configuraci√≥n Global (DEBE coincidir con el entrenamiento) ---
N_LAGS = 3  # Aseg√∫rate que este valor es el mismo que en tu entrenamiento
WINDOW_SIZE = 24 # Aseg√∫rate que este valor es el mismo
HORAS_POR_DIA_PREDICCION = 24 # Asumimos predicciones horarias

# Carga de datos hist√≥ricos (necesario para iniciar la secuencia de predicci√≥n)
try:
    df_global = pd.read_csv('aire_new.csv', sep=',', parse_dates=['timestamp_captura'], dayfirst=True)
    df_global = df_global.rename(columns={'timestamp_captura': 'Fecha', 'objectid': 'objectId'})
    df_global['Fecha'] = pd.to_datetime(df_global['Fecha'], errors='coerce', dayfirst=True)
    numeric_cols_to_check = ['so2', 'no2', 'o3', 'co', 'pm10', 'pm25'] #A√±ade 'no2' si es una feature
    for col in numeric_cols_to_check:
        if col in df_global.columns:
            df_global[col] = pd.to_numeric(df_global[col], errors='coerce')
    print("üìä Datos hist√≥ricos cargados para predicciones multi-d√≠a.")
except FileNotFoundError:
    print("‚ùå Error: No se encontr√≥ 'aire_new.csv'. Necesitas los datos hist√≥ricos.")
    df_global = None

def generar_predicciones_3_dias(object_id, fecha_inicio_str, historical_df):
    """
    Genera predicciones de O3 para los pr√≥ximos 3 d√≠as (72 horas) para un objectId.

    Args:
        object_id (int): El ID de la zona.
        fecha_inicio_str (str): La fecha/hora de inicio para la primera predicci√≥n
                                (ej. '2025-04-25 00:00:00'). Las predicciones comenzar√°n
                                DESPU√âS de esta hora.
        historical_df (pd.DataFrame): DataFrame con todos los datos hist√≥ricos.

    Returns:
        str: Un JSON con las predicciones horarias, o None si hay error.
    """
    if historical_df is None:
        print("‚ùå Error: Datos hist√≥ricos no disponibles.")
        return None

    fecha_inicio_prediccion = pd.to_datetime(fecha_inicio_str)

    # --- 1. Cargar Modelo y Escalador Espec√≠fico del objectId ---
    model_file = None
    scaler_file = f"escalador_{object_id}.pkl"
    # Asumimos que el nombre del modelo incluye el object_id y el nombre del algoritmo
    # Ejemplo: modelo_12_xgboost.pkl (necesitar√°s buscar el nombre exacto)
    
    # Busca el modelo (puedes tener una l√≥gica m√°s robusta para obtener el "mejor" modelo)
    archivos_modelo_oid = [f for f in os.listdir('.') if f.startswith(f"modelo_{object_id}_") and f.endswith(".pkl")]
    if not archivos_modelo_oid:
        print(f"‚ùå Error: No se encontr√≥ ning√∫n archivo de modelo para objectId {object_id}.")
        return None
    model_file = archivos_modelo_oid[0] # Tomamos el primero que encuentre, idealmente sabr√≠as cu√°l es el mejor
    
    if not os.path.exists(model_file) or not os.path.exists(scaler_file):
        print(f"‚ùå Error: No se encontr√≥ el archivo de modelo '{model_file}' o el escalador '{scaler_file}'.")
        return None

    try:
        with open(model_file, 'rb') as f:
            model = pickle.load(f)
        with open(scaler_file, 'rb') as f:
            scaler = pickle.load(f)
        print(f"‚úÖ Modelo '{model_file}' y escalador '{scaler_file}' cargados para objectId {object_id}.")
    except Exception as e:
        print(f"‚ùå Error cargando archivos para {object_id}: {e}")
        return None

    # --- 2. Preparar Datos Hist√≥ricos Iniciales ---
    df_zona_hist = historical_df[historical_df['objectId'] == object_id].copy()
    df_zona_hist.sort_values(by='Fecha', inplace=True)
    
    # Tomamos los datos hist√≥ricos justo ANTES de la fecha de inicio de la predicci√≥n
    # Necesitamos suficientes datos para los lags y la ventana m√≥vil inicial
    datos_para_inicio = df_zona_hist[df_zona_hist['Fecha'] < fecha_inicio_prediccion].tail(WINDOW_SIZE + N_LAGS + 5)

    if len(datos_para_inicio) < max(N_LAGS, WINDOW_SIZE):
        print(f"‚ùå Error: No hay suficientes datos hist√≥ricos ({len(datos_para_inicio)}) para {object_id} antes de {fecha_inicio_str} para calcular lags/ventanas iniciales.")
        return None

    # Lista para guardar las predicciones [{fecha, o3_predicho}]
    predicciones_list = []
    
    # Copia de los datos recientes para ir actualizando con las predicciones
    # Esta serie `current_o3_series` mantendr√° los √∫ltimos valores de o3 (reales y luego predichos)
    current_o3_series = datos_para_inicio['o3'].dropna().copy()
    # Datos ex√≥genos recientes para usarlos como base para el futuro (¬°GRAN SUPOSICI√ìN!)
    columnas_features_base = [col for col in datos_para_inicio.select_dtypes(include=np.number).columns if col not in ['Fecha', 'o3', 'objectId']]
    latest_exog_features = datos_para_inicio[columnas_features_base].iloc[-1].copy() # Tomamos la √∫ltima fila de ex√≥genas
    
    # Si alguna ex√≥gena es NaN en la √∫ltima fila, rellenar con la media de esa columna en `datos_para_inicio`
    for col in columnas_features_base:
        if pd.isna(latest_exog_features[col]):
            mean_val = datos_para_inicio[col].mean()
            latest_exog_features[col] = mean_val if pd.notna(mean_val) else 0 # Rellena con media o 0


    # --- 3. Bucle de Predicci√≥n Secuencial (hora a hora) ---
    current_timestamp = fecha_inicio_prediccion
    for _ in range(3 * HORAS_POR_DIA_PREDICCION): # 3 d√≠as * 24 horas/d√≠a
        input_features = {}
        
        # Caracter√≠sticas Temporales (para el current_timestamp)
        input_features['hora'] = current_timestamp.hour
        input_features['dia_semana'] = current_timestamp.dayofweek
        input_features['mes'] = current_timestamp.month
        input_features['dia_del_anio'] = current_timestamp.dayofyear

        # Lags (de current_o3_series, que se actualiza)
        if len(current_o3_series) < N_LAGS:
            # Rellenar si no hay suficientes datos para lags (esto podr√≠a pasar al inicio si hay muchos NaNs)
            # Podr√≠as usar la media general de o3 de la zona, o el √∫ltimo valor conocido
            mean_o3_hist = current_o3_series.mean() if not current_o3_series.empty else 0
            padded_o3 = np.pad(current_o3_series.values, (N_LAGS - len(current_o3_series), 0), 'constant', constant_values=mean_o3_hist)
            for i in range(1, N_LAGS + 1):
                input_features[f'o3_lag_{i}'] = padded_o3[-i]
        else:
            for i in range(1, N_LAGS + 1):
                input_features[f'o3_lag_{i}'] = current_o3_series.iloc[-i]
        
        # Ventanas M√≥viles (de current_o3_series)
        # Para la ventana m√≥vil, tomamos los datos ANTERIORES al paso actual (equivalente al shift(1) del entrenamiento)
        if len(current_o3_series) >= 1: # Necesita al menos 1 valor para el shift
            rolling_window_data = current_o3_series.iloc[-min(len(current_o3_series), WINDOW_SIZE):] # Los √∫ltimos WINDOW_SIZE puntos de la serie actual
            input_features['o3_rolling_mean'] = rolling_window_data.mean()
            input_features['o3_rolling_std'] = rolling_window_data.std()
        else: # No hay datos para rolling window
            input_features['o3_rolling_mean'] = current_o3_series.mean() if not current_o3_series.empty else 0 # O alg√∫n otro valor por defecto
            input_features['o3_rolling_std'] = 0


        # Rellenar NaN en rolling_std (si la varianza es 0 o pocos puntos)
        if pd.isna(input_features['o3_rolling_std']):
            input_features['o3_rolling_std'] = 0
        if pd.isna(input_features['o3_rolling_mean']): # Si la media tambi√©n es NaN (serie vac√≠a)
            input_features['o3_rolling_mean'] = 0


        # Variables Ex√≥genas (usamos latest_exog_features)
        # ¬°SUPOSICI√ìN!: mantenemos constantes las √∫ltimas observadas o podr√≠as aplicarles alguna tendencia/ciclo
        for col_base in columnas_features_base:
            input_features[col_base] = latest_exog_features[col_base]

        # Crear DataFrame para la predicci√≥n
        try:
            # Usar feature_names_in_ del escalador, que deber√≠a tenerlas
            model_columns = scaler.feature_names_in_
        except AttributeError:
            print("‚ùå Error: El escalador no tiene 'feature_names_in_'. No se puede determinar el orden de las columnas. Guarda las columnas durante el entrenamiento.")
            return None # No se puede continuar si no conocemos las columnas exactas

        input_df_single_row = pd.DataFrame([input_features])
        # Reordenar y asegurar que todas las columnas del modelo est√°n presentes, rellenando con 0 si falta alguna (aunque no deber√≠a si usamos las ex√≥genas)
        input_df_single_row = input_df_single_row.reindex(columns=model_columns, fill_value=0) 


        # Escalar y Predecir
        input_scaled = scaler.transform(input_df_single_row)
        predicted_o3 = model.predict(input_scaled)[0]
        
        # Guardar predicci√≥n
        predicciones_list.append({
            "fecha": current_timestamp.strftime('%Y-%m-%d %H:%M:%S'),
            "o3_predicho": round(float(predicted_o3), 2) # Convertir a float nativo para JSON
        })
        
        # Actualizar current_o3_series con la nueva predicci√≥n para el siguiente paso
        # Creamos una nueva serie para evitar problemas de √≠ndice con pd.concat
        new_o3_value_series = pd.Series([predicted_o3])
        current_o3_series = pd.concat([current_o3_series, new_o3_value_series], ignore_index=True)
        # Mantenemos solo los √∫ltimos N necesarios para no crecer indefinidamente
        if len(current_o3_series) > (WINDOW_SIZE + N_LAGS + 5) :
             current_o3_series = current_o3_series.iloc[-(WINDOW_SIZE + N_LAGS + 5):]


        # Avanzar al siguiente timestamp (1 hora)
        current_timestamp += timedelta(hours=1)
        
    return json.dumps(predicciones_list, indent=4)


# --- Ejemplo de Uso ---
if df_global is not None:
    # Elige un objectId para el que tengas un modelo guardado
    # Busca un ID viable que tenga modelo guardado
    id_a_predecir_multidia = None
    for f_name in os.listdir('.'):
        if f_name.startswith("modelo_") and f_name.endswith(".pkl"):
            try:
                # Extrae el ID del nombre del archivo, por ejemplo: "modelo_12_xgboost.pkl" -> 12
                id_test = int(f_name.split('_')[1]) 
                # Comprobar si tambi√©n existe el escalador
                if os.path.exists(f"escalador_{id_test}.pkl"):
                    id_a_predecir_multidia = id_test
                    print(f"üí° Usando ObjectId {id_a_predecir_multidia} para predicci√≥n multi-d√≠a (modelo encontrado: {f_name}).")
                    break
            except (IndexError, ValueError):
                # El nombre del archivo no tiene el formato esperado
                continue
    
    if id_a_predecir_multidia is not None:
        # Tomar la √∫ltima fecha disponible para ese objectId como referencia
        ultima_fecha_conocida_obj = df_global[df_global['objectId'] == id_a_predecir_multidia]['Fecha'].max()
        if pd.isna(ultima_fecha_conocida_obj):
            print(f"‚ö†Ô∏è No se pudo determinar la √∫ltima fecha conocida para objectId {id_a_predecir_multidia}. Usando fecha por defecto.")
            fecha_de_inicio_predicciones = "2025-04-25 00:00:00" # Cambia esto si es necesario
        else:
            # Iniciamos predicciones justo despu√©s de la √∫ltima fecha conocida
            fecha_de_inicio_predicciones = (ultima_fecha_conocida_obj + timedelta(hours=1)).strftime('%Y-%m-%d %H:%M:%S')

        print(f"üìÖ Solicitando predicciones para ObjectId {id_a_predecir_multidia} a partir de {fecha_de_inicio_predicciones}")
        
        json_predicciones = generar_predicciones_3_dias(id_a_predecir_multidia, fecha_de_inicio_predicciones, df_global)
        
        if json_predicciones:
            print("\n--- JSON de Predicciones (pr√≥ximos 3 d√≠as)---")
            print(json_predicciones)
            
            # Para cargarlo como gr√°fico, normalmente pasar√≠as este JSON a una librer√≠a de JS (Chart.js, D3.js, etc.)
            # En Python, para una visualizaci√≥n r√°pida:
            try:
                import matplotlib.pyplot as plt
                df_plot = pd.read_json(json_predicciones)
                df_plot['fecha'] = pd.to_datetime(df_plot['fecha'])
                plt.figure(figsize=(15, 6))
                plt.plot(df_plot['fecha'], df_plot['o3_predicho'], marker='o', linestyle='-')
                plt.title(f'Predicci√≥n O3 (3 d√≠as) para ObjectId {id_a_predecir_multidia}')
                plt.xlabel('Fecha')
                plt.ylabel('O3 Predicho (¬µg/m¬≥)')
                plt.grid(True)
                plt.xticks(rotation=45)
                plt.tight_layout()
                plt.show()
            except ImportError:
                print("\n(Para graficar directamente en Python, instala matplotlib: pip install matplotlib)")
            except Exception as e_plot:
                print(f"\nError al intentar graficar: {e_plot}")
        else:
            print(f"\n‚ùå No se pudieron generar las predicciones para ObjectId {id_a_predecir_multidia}.")
    else:
        print("‚ùå No se encontr√≥ ning√∫n objectId con modelo y escalador guardados para realizar la predicci√≥n multi-d√≠a.")